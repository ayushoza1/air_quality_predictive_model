{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from pandas.core.frame import DataFrame\n",
    "import requests\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import openaq\n",
    "import warnings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openaq\n",
    "import requests\n",
    "from datetime import datetime as dt\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from meteostat import Point\n",
    "from meteostat import Daily \n",
    "\n",
    "cities_of_interest = {\"Akureyri\": \"IS\", \"London\": \"GB\", \n",
    "    \"Mexico City\": \"MX\", \"Newcastle\": \"GB\", \"Reykjavík\":\"IS\"}\n",
    "data_dirs = {\"weather\": \"data/weather\", \"pollution\": \"data/pollution\"}\n",
    "\n",
    "def fetch_weather_data(city_name, date_from=date.today() - timedelta(30), date_to=date.today()):\n",
    "    ''' Fetch weather measurements for a particular city during a particular time.\n",
    "\n",
    "    '''\n",
    "    #We limit to the 5 cities above\n",
    "    city_country = get_city_country(city_name)\n",
    "\n",
    "    #Since both the weather api and pandas dataframe operate on the datetime level\n",
    "    #cast date to datetime early \n",
    "    dt_from = cast_date_to_datetime(date_from)\n",
    "    dt_to = cast_date_to_datetime(date_to)\n",
    "\n",
    "    weather = fetch_data_from_csv('weather', city_country[0], dt_from= dt_from, dt_to=dt_to)\n",
    "\n",
    "    if(weather.empty):\n",
    "        weather = fetch_data_from_api('weather', city_country, dt_from, dt_to)\n",
    "    #The complicated case is: a file exists but not all the data is there\n",
    "    elif(needs_more_data(weather, dt_from, dt_to)):\n",
    "        weather = partial_csv_update('weather', weather, city_country)\n",
    "    return weather\n",
    "\n",
    "def fetch_pollution_data(city_name, date_from=date.today() - timedelta(days=30), date_to=date.today()):\n",
    "\n",
    "    city_country = get_city_country(city_name)\n",
    "\n",
    "    #Since both the weather api and pandas dataframe operate on the datetime level\n",
    "    #cast date to datetime early \n",
    "    dt_from = cast_date_to_datetime(date_from)\n",
    "    dt_to = cast_date_to_datetime(date_to)\n",
    "\n",
    "    pollution = fetch_data_from_csv('pollution', city_country[0], dt_from = dt_from, dt_to = dt_to)\n",
    "\n",
    "    if(pollution.empty):\n",
    "        pollution = fetch_data_from_api('pollution', city_country, dt_from, dt_to)\n",
    "    elif(needs_more_data(pollution, dt_from, dt_to)):\n",
    "        pollution = partial_csv_update('pollution', pollution, city_country)\n",
    "    return pollution \n",
    "\n",
    "def cast_date_to_datetime(date):\n",
    "    midnight_time = dt.min.time()\n",
    "    return dt.combine(date, midnight_time)\n",
    "\n",
    "def needs_more_data(data, dt_from, dt_to):\n",
    "    delta_days = (dt_to - dt_from).days + 1\n",
    "    data_subset = data[(dt_from <= data.index) & (data.index <= dt_to)]\n",
    "    return len(data_subset) < delta_days\n",
    "\n",
    "def get_city_country(city_name):\n",
    "    if city_name not in cities_of_interest.keys():\n",
    "        raise Exception(f\"Please enter one of {cities_of_interest}.\")\n",
    "    return (city_name, cities_of_interest[city_name])\n",
    "\n",
    "def fetch_data_from_csv(type, city_name, **kwargs):\n",
    "    file_dir = data_dirs[type]\n",
    "    \n",
    "    #Empty dataframe for when there is no csv file\n",
    "    data = pd.DataFrame({'' : []})\n",
    "\n",
    "    try:\n",
    "        data = pd.read_csv(f'{file_dir}/{city_name}.csv', index_col='date', parse_dates=['date'])\n",
    "        if (kwargs):\n",
    "            return data[(kwargs['dt_from'] <= data.index) & (data.index <= kwargs['dt_to'])]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No historical {type} data found locally. Using API to get fresh data.\\n\")\n",
    "    return data\n",
    "\n",
    "def fetch_data_from_api(type, city_and_country, date_from, date_to):\n",
    "    # The first part of the tuple is the city and our csv data is organized by city name.\n",
    "    city_coords = query_lat_long(city_and_country)\n",
    "\n",
    "    if(type=='weather'):\n",
    "        data = query_historical_weather(city_coords, date_from, date_to)\n",
    "    elif(type=='pollution'):\n",
    "        data = query_historical_polluiton(city_and_country, date_from, date_to)\n",
    "\n",
    "    #Write new csv file\n",
    "    dir_name = data_dirs[type]\n",
    "    data.to_csv(f'{dir_name}/{city_and_country[0]}.csv')\n",
    "    return data\n",
    "\n",
    "def partial_csv_update(type, from_api, city_and_country):\n",
    "    #Note that this is all of our CSV data for the city. no time filter\n",
    "    from_file = fetch_data_from_csv(type, city_and_country[0])\n",
    "\n",
    "    total_data = pd.concat([from_file, from_api])\n",
    "    unique_days = total_data.drop_duplicates()\n",
    "    unique_days = unique_days.sort_values('date')\n",
    "\n",
    "    dir_name = data_dirs[type]\n",
    "    unique_days.to_csv(f'{dir_name}/{city_and_country[0]}.csv')\n",
    "    return unique_days\n",
    "\n",
    "def filter_results_to_country(geoapi_response_data, country):\n",
    "    #If there are multiple cities with the same name, we choose the most populated\n",
    "    filter_by_country = [resp for resp in geoapi_response_data if resp['country_code'] == country]\n",
    "    # \n",
    "    sorted_by_pop = sorted(filter_by_country, key = lambda resp: resp['population'] if 'population' in resp else 0, reverse=True)\n",
    "    result = sorted_by_pop[0]\n",
    "\n",
    "    # Relevant subset of the result dict\n",
    "    return {key: result[key] for key in ('latitude', 'longitude', 'elevation', 'population')}\n",
    "\n",
    "def query_lat_long(city_country):\n",
    "    params_dict = {\n",
    "        'name': city_country[0],\n",
    "        #Default is 10 but since newcastle gives 9, we might hit the limit\n",
    "        'count': 100\n",
    "    }\n",
    "\n",
    "    # Since the user gives us more than 3 chars, the api performs fuzzy matching. So we do not\n",
    "    # need to worry abt spelling\n",
    "    resp = requests.get('https://geocoding-api.open-meteo.com/v1/search', params_dict)\n",
    "    data = resp.json()\n",
    "    \n",
    "    return filter_results_to_country(data['results'], city_country[1])\n",
    "\n",
    "def query_historical_weather(lat_long_elevation, date_from, date_to):\n",
    "    # Since we have dates and the api uses time, we need to convert from date to datetime\n",
    "    midnight_time = dt.min.time()\n",
    "    dt_from = dt.combine(date_from, midnight_time)\n",
    "    dt_to = dt.combine(date_to, midnight_time)\n",
    "    \n",
    "    location = Point(\n",
    "        lat_long_elevation['latitude'], \n",
    "        lat_long_elevation['longitude'], \n",
    "        lat_long_elevation['elevation'])\n",
    "\n",
    "    daily = Daily(location, start=dt_from, end=dt_to)\n",
    "    \n",
    "    # Ask meteostat to fill in any gaps in the data\n",
    "    daily.normalize()\n",
    "    data = daily.fetch()\n",
    "    \n",
    "    #tavg=Temp average (C).prcp=Total precipitation(mm). wdir=Wind direction(degrees)\n",
    "    #wspd=Average wind speed(km/h).wpgt=Wind peak gust(km/hr). pres=Sea-level air pressure(hpa)\n",
    "    #rhum=Relative humidity(does not work)\n",
    "    response = data[['tavg', 'prcp', 'wdir', 'wspd', 'wpgt', 'pres']]\n",
    "\n",
    "    #Since time is an index, simply calling rename does not work\n",
    "    tidy = response.rename_axis(index={\"time\": \"date\"})\n",
    "\n",
    "    return tidy\n",
    "\n",
    "def get_weather(city_country):\n",
    "    coords = query_lat_long(city_country)\n",
    "    return query_historical_weather(coords)\n",
    "\n",
    "\n",
    "#From fetching measurements data notebook\n",
    "\n",
    "# TODO\n",
    "# 1. Drop the ID column, don't need to write that into the file\n",
    "# 2. The dates are not the same for all cities.. Look into that\n",
    "# 3. Maybe count locations and provide that into the dataframe as well. \n",
    "#    It's relevent to know how many measures are in the city.\n",
    "# 4. Can we choose certain type of measures\n",
    "\n",
    "# Filter what city we want to get\n",
    "def filter_results_to_country(geoapi_response_data, country):\n",
    "    #If there are multiple cities with the same name, we choose the most populated\n",
    "    filter_by_country = [resp for resp in geoapi_response_data if resp['country_code'] == country]\n",
    "    # \n",
    "    sorted_by_pop = sorted(filter_by_country, key = lambda resp: resp['population'] if 'population' in resp else 0, reverse=True)\n",
    "    result = sorted_by_pop[0]\n",
    "\n",
    "    # Relevant subset of the result dict\n",
    "    return {key: result[key] for key in ('latitude', 'longitude', 'elevation', 'population')}\n",
    "\n",
    "def query_historical_polluiton(city_country, date_from, date_to):\n",
    "    '''\n",
    "    This function takes in a city, parameter and date and writes data into a csv.file\n",
    "    Input:\n",
    "        city: name of a city (string)\n",
    "        ???parameter: List of strings that represent the parameters wanted to calculate\n",
    "        date_from: measurments after this date will be calculated\n",
    "        date_to: Measures until this date will be calculated\n",
    "    '''\n",
    "    \n",
    "    # Explicitly use v2 of the api http://dhhagan.github.io/py-openaq/api.html\n",
    "    api = openaq.OpenAQ(version ='v2')\n",
    "    # Get the longitude and latitude for the city\n",
    "    location = query_lat_long(city_country)\n",
    "    coords = f'{location[\"latitude\"]},{location[\"longitude\"]}'\n",
    "    \n",
    "    # Call the location api to check for the first date updated\n",
    "    locations = api.locations(coordinates = coords,radius = 10000,df = True)\n",
    "\n",
    "    min_date = locations[\"firstUpdated\"].min()\n",
    "    min_date = min_date.tz_convert(None)\n",
    "    min_date = pd.to_datetime(min_date) \n",
    "    \n",
    "    if min_date > date_from:\n",
    "        date_from = min_date  \n",
    "    \n",
    "    # Number of days we want measurements for\n",
    "    day_diff = (date_to - date_from).days\n",
    "    \n",
    "    # How we split the call between days to the API\n",
    "    split_days = 30\n",
    "\n",
    "    # Number of 30 day blocks in our range\n",
    "    number_months = day_diff // split_days\n",
    "\n",
    "    # Initialize the start date\n",
    "    start = date_from\n",
    "\n",
    "    # Add measurements data frame 30 days at a time\n",
    "    # An extra iteration for the remaining <30 days\n",
    "    for n in range(number_months + 1):\n",
    "        \n",
    "        # Find the end date\n",
    "        end = start + timedelta(days = split_days)\n",
    "        \n",
    "        # Fetch the data from the measurment api\n",
    "        df_api = api.measurements(coordinates = coords, radius = 5000, df = True, \n",
    "                                  limit = 30000, parameter = [\"pm25\", \"pm10\"], value_from = 0,\n",
    "                              date_from = start, date_to = end)\n",
    "        \n",
    "        # Start as the last end date\n",
    "        start = end\n",
    "\n",
    "        # For the first iteration create df\n",
    "        if n == 0: \n",
    "            df = df_api.copy()\n",
    "        # After the first iteration append the data\n",
    "        else:\n",
    "            df = df.append(df_api)\n",
    "    \n",
    "    ## Data prepping \n",
    "\n",
    "    # Change the index\n",
    "    df.index.name = 'Date.local'\n",
    "    df.reset_index(inplace=True)\n",
    "    df['date'] = df['Date.local'].dt.strftime('%Y-%m-%d')\n",
    "    df['value'] = df['value'].astype(float, errors = 'raise')\n",
    "\n",
    "    # Calculate mean, max and min value for each date\n",
    "    Result_mean = df.groupby(['date', 'parameter'],as_index=False)['value'].mean()\n",
    "    Result_max = df.groupby(['date', 'parameter'],as_index=False)['value'].max()\n",
    "    Result_min = df.groupby(['date', 'parameter'],as_index=False)['value'].min()\n",
    "\n",
    "    # Pivot the tables to wide format\n",
    "    ResultWide_mean = Result_mean.pivot_table(index='date',columns='parameter', values='value')\n",
    "    ResultWide_max = Result_max.pivot_table(index='date',columns='parameter', values='value')\n",
    "    ResultWide_min = Result_min.pivot_table(index='date',columns='parameter', values='value')\n",
    "\n",
    "    # Rename the columns to distinguish\n",
    "    ResultWide_mean.rename(columns={\"pm10\": 'pm10_mean', 'pm25': 'pm25_mean'}, inplace=True)\n",
    "    ResultWide_max.rename(columns={\"pm10\": 'pm10_max', 'pm25': 'pm25_max'}, inplace=True)\n",
    "    ResultWide_min.rename(columns={\"pm10\": 'pm10_min', 'pm25': 'pm25_min'}, inplace=True)\n",
    "\n",
    "    # Join mean and max first\n",
    "    df_first_join = pd.merge(ResultWide_mean, ResultWide_max, left_index=True, right_index=True)\n",
    "\n",
    "    # Join now to min\n",
    "    ResultWide = pd.merge(df_first_join, ResultWide_min, left_index=True, right_index=True)\n",
    "\n",
    "    # Change the index (Can we drop the ID column?)\n",
    "    ResultWide.index.name = 'date'\n",
    "    ResultWide.reset_index(inplace=True)\n",
    "    ResultWide.index.name = 'ID'\n",
    "\n",
    "    return ResultWide \n",
    "    \n",
    "# # Call the function\n",
    "# city = 'London'\n",
    "# date_from = pd.to_datetime('2020-01-01') \n",
    "# date_to = pd.to_datetime('2021-05-01')\n",
    "\n",
    "# #measurement_to_csv(city,date_from,date_to)\n",
    "# weather_data = fetch_weather_data(city, date_from=date.today() - timedelta(days=365))\n",
    "# pollution_data = fetch_pollution_data(city)\n",
    "\n",
    "# fubbus = \"Fubbus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pm10_mean</th>\n",
       "      <th>pm25_mean</th>\n",
       "      <th>pm10_max</th>\n",
       "      <th>pm25_max</th>\n",
       "      <th>pm10_min</th>\n",
       "      <th>pm25_min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>22.423077</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>1</td>\n",
       "      <td>13.071429</td>\n",
       "      <td>10.222222</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>2</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>8.873239</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>3</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.507246</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>4</td>\n",
       "      <td>6.156250</td>\n",
       "      <td>6.006667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-08</th>\n",
       "      <td>95</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.136364</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-09</th>\n",
       "      <td>96</td>\n",
       "      <td>14.888889</td>\n",
       "      <td>7.866667</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-10</th>\n",
       "      <td>97</td>\n",
       "      <td>14.052632</td>\n",
       "      <td>8.275862</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-11</th>\n",
       "      <td>98</td>\n",
       "      <td>12.586207</td>\n",
       "      <td>7.136364</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-12</th>\n",
       "      <td>99</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>8.779661</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  pm10_mean  pm25_mean  pm10_max  pm25_max  pm10_min  pm25_min\n",
       "date                                                                        \n",
       "2021-01-01   0  22.423077  20.475000      25.0      24.0      18.0      16.0\n",
       "2021-01-02   1  13.071429  10.222222      24.0      22.0       8.0       6.0\n",
       "2021-01-03   2   8.666667   8.873239      10.0      10.0       8.0       7.0\n",
       "2021-01-04   3   8.000000   8.507246       9.0      15.0       7.0       5.0\n",
       "2021-01-05   4   6.156250   6.006667       7.0      15.0       1.5       0.3\n",
       "...         ..        ...        ...       ...       ...       ...       ...\n",
       "2021-04-08  95  12.000000   7.136364      12.0       8.0      12.0       6.0\n",
       "2021-04-09  96  14.888889   7.866667      19.0      10.0      12.0       7.0\n",
       "2021-04-10  97  14.052632   8.275862      16.0      10.0      11.0       7.0\n",
       "2021-04-11  98  12.586207   7.136364      16.0       9.0      10.0       5.0\n",
       "2021-04-12  99  11.384615   8.779661      15.0      12.0       8.0       6.0\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the city\n",
    "city = 'London'\n",
    "date_from = pd.to_datetime('2021-01-01') \n",
    "date_to = pd.to_datetime('2021-05-01')\n",
    "\n",
    "Measurements = fetch_pollution_data(city, date_from = date_from, date_to= date_to)\n",
    "Measurements.head(100)\n",
    "#Measurements\n",
    "# You need the csv.files for the city\n",
    "#Measurements = pd.read_csv(f'Data_measurements/{city}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/pp-proj2/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c1ad4e578d35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMeasurements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMeasurements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pm10_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#sns.scatterplot(x=\"pm10_max\", y=\"pm10_mean\", data=Measurements)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#plt.xticks(rotation=15)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.title('Daily pm10 levels in London')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pp-proj2/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pp-proj2/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "plt.scatter(Measurements['dat'], Measurements['pm10_mean'])\n",
    "#sns.scatterplot(x=\"pm10_max\", y=\"pm10_mean\", data=Measurements)\n",
    "#plt.xticks(rotation=15)\n",
    "#plt.title('Daily pm10 levels in London')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             int64\n",
       "pm10_mean    float64\n",
       "pm25_mean    float64\n",
       "pm10_max     float64\n",
       "pm25_max     float64\n",
       "pm10_min     float64\n",
       "pm25_min     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Measurements.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
