{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd396d2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "During the 2021 United Nations Climate Change Conference a report was published stating that 'Air pollution is the largest environmental risk to the public’s health, contributing to cardiovascular disease, lung cancer and respiratory diseases. It is costing the UK economy £20 billion a year and contributes to over 25,000 deaths a year' $^{1}$. However, this report could be masking a bigger issue of air polution worldwide. An OECD report published in 2016 states that air pollution costs 1% of GDP each year and accounts for 9 million premature deaths $^{2}$.\n",
    "\n",
    "With the human population growing at an exponential rate, it would seem, we now find ourselves in a continous loop. The Malthusian model, commonly used in development econmics, looks to model population growth. As a country grows food production, basic industry and infrastructure grow to service the population until an equilibrium level is reached. There are two takeaways from the model relating to air pollution. Firstly, air pollution does not cost and is in essence free to 'produce' implying there is no constraint on air pollution. Moreover, as less economically developed countries accelerate towards their equilibrium state, industry will have to keep up and air pollution is predicted to get worse.\n",
    "\n",
    "This being said, there appears to be other factors that affect air pollution. Global warming is well documented, however, the secondary and tertiary impacts on air pollution are less clear. Wildfires raged across Greece in August 2021, with the problem stemming from unusually hot and long summers. The Guardian reported that 'the fires were some of the worst on record' $^{3}$. Wildfires produce high amounts of black carbon, carbon dioxide, ozone precursors and black carbon into the atmosphere, causing air quality to plummet. \n",
    "\n",
    "However, with evolving winds, humidity levels and precipitation rates, areas once crippled by air pollution may soon see clearer skies while air pollution is involuntarily dumped onto other cities in a game of air pollution roulette. \n",
    "\n",
    "In this report we will look in depth at the factors above namely: demographics, weather and events. The report will aim to highlight areas of interest related to these factors in three countries: Mexico, UK and Iceland - representing an emerging nation and two developed nations with very different weather dynamics, industry and natural resources.  \n",
    "\n",
    "The report will focus upon 2 key measurements particulate matter 10 (pm10) and particulate matter 25 (pm25) these are defined as particulate matter that is smaller than 10 micrometres and 25 micrometres respecitivley. These were chosen given the breadth of activities that produce pm10 and pm25. The main contributor to pm10 and pm25 is the burning of oil, fuel and wood, however, pm25 and pm10 also include dust from industrial activity, landfill sites and even smaller bacteria. The wide range of polluting activities emitting these particulates will allow us to examine, explore and analyse the three nations in depth. \n",
    "\n",
    "Finally, we aim to predict air quality in a certain city for a certain day given the weather conditions using simple regression model.\n",
    "\n",
    "\n",
    "\n",
    "$^{1}$ http://www.local.gov.uk/parliament/briefings-and-responses/cop26-and-impact-air-pollution-public-health-and-wellbeing-house\n",
    "\n",
    "$^{2}$ OECD (2016), The Economic Consequences of Outdoor Air Pollution, OECD Publishing, Paris, https://doi.org/10.1787/9789264257474-en.\n",
    "\n",
    "$^{3}$ https://www.theguardian.com/world/2021/sep/30/its-like-a-war-greece-battles-increase-in-summer-wildfires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8f2b5",
   "metadata": {},
   "source": [
    "# Data & Measurements\n",
    "\n",
    "Most of the data in this report and prediction model comes from two apis. One for weather and one for pollution.\n",
    "We wrapped both of them in functions that call the apis, parse the response and return appropriate data frames.\n",
    "In addition to returning the data asked for, our functions also store the data in CSV files under ./data in the project directory. This is done to reduce network requests and also to be able to verify and play around with the data in raw format when exploring it. \n",
    "<br>If a csv file exists for the city the user asks for, and it contains all the rows for the queried dates, they are returned and the api is not called.\n",
    "\n",
    "We also have yearly population data. That is stored locally in csv files, no api there(something more plz).\n",
    "\n",
    "## Weather\n",
    "The source for weather data is the meteostat api found here https://dev.meteostat.net/python/. It has a convenient python library that allows the user to query for historical weather data for a particular location during a specified time interval.\n",
    "The python library even automatically collects data from different weather stations and bundles them together. \n",
    "For the purpose of this report, we need to transform the data a bit before using it. For example, we are only interested in a subset of all the data in the response. Furthermore, to ease usage of our model, our users should only provide a city name but the meteostat library only accepts latitude and longitude coordinates. \n",
    "To facilitate that, prior to using the meteostat api, we call a geocoding api from open-meteo.com [https://open-meteo.com/en/docs/geocoding-api]. It accepts a city name and returns all cities that match the name and their geographic latitude and longitude coordinates. \n",
    "\n",
    "The results from the open-meteo api are global. This means that if multiple cities share the same name, they are all in the API response. Because of this, we filter the results down to a particular country, and assume that if our user ask for 'London' she means London UK, not London New York USA. In addition, of all the cities that match a given country, we assume the user wants the most populated city.\n",
    "\n",
    "Armed with the latitude and longitude for the city the user wants to know about, we then finally call the meteostat api. \n",
    "As mentioned before, if we already have CSV data locally for the range, instead of going through all that was mentioned above,\n",
    "we just return appropriate data from the CSV file.\n",
    "\n",
    "## Pollution\n",
    "\n",
    "Pollution data is taken from \n",
    "\n",
    "\n",
    "## Demography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db5f8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pandas.core.frame import DataFrame\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import openaq\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from meteostat import Point\n",
    "from meteostat import Daily \n",
    "# Focus on these 5 cities and document their contry code\n",
    "cities_of_interest = {\"Akureyri\": \"IS\", \"London\": \"GB\", \n",
    "    \"Mexico City\": \"MX\", \"Newcastle\": \"GB\", \"Reykjavík\":\"IS\"}\n",
    "data_dirs = {\"weather\": \"data/weather\", \"pollution\": \"data/pollution\"}\n",
    "\n",
    "def fetch_weather_data(city_name, date_from=date.today() - timedelta(30), date_to=date.today()):\n",
    "    ''' Fetch weather measurements for a particular city during a particular time.\n",
    "\n",
    "    '''\n",
    "    #We limit to the 5 cities above\n",
    "    city_country = get_city_country(city_name)\n",
    "\n",
    "    #Since both the weather api and pandas dataframe operate on the datetime level\n",
    "    #cast date to datetime early \n",
    "    dt_from = cast_date_to_datetime(date_from)\n",
    "    dt_to = cast_date_to_datetime(date_to)\n",
    "\n",
    "    weather = fetch_data_from_csv('weather', city_country[0], dt_from= dt_from, dt_to=dt_to)\n",
    "\n",
    "    if(weather.empty):\n",
    "        weather = fetch_data_from_api('weather', city_country, dt_from, dt_to)\n",
    "    #The complicated case is: a file exists but not all the data is there\n",
    "    elif(needs_more_data(weather, dt_from, dt_to)):\n",
    "        weather = partial_csv_update('weather', weather, city_country)\n",
    "    return weather\n",
    "\n",
    "def fetch_pollution_data(city_name, date_from=date.today() - timedelta(days=30), date_to=date.today()):\n",
    "\n",
    "    city_country = get_city_country(city_name)\n",
    "\n",
    "    #Since both the weather api and pandas dataframe operate on the datetime level\n",
    "    #cast date to datetime early \n",
    "    dt_from = cast_date_to_datetime(date_from)\n",
    "    dt_to = cast_date_to_datetime(date_to)\n",
    "\n",
    "    pollution = fetch_data_from_csv('pollution', city_country[0], dt_from = dt_from, dt_to = dt_to)\n",
    "\n",
    "    if(pollution.empty):\n",
    "        pollution = fetch_data_from_api('pollution', city_country, dt_from, dt_to)\n",
    "    elif(needs_more_data(pollution, dt_from, dt_to)):\n",
    "        pollution = partial_csv_update('pollution', pollution, city_country)\n",
    "    return pollution \n",
    "\n",
    "def cast_date_to_datetime(date):\n",
    "    midnight_time = dt.min.time()\n",
    "    return dt.combine(date, midnight_time)\n",
    "\n",
    "def needs_more_data(data, dt_from, dt_to):\n",
    "    delta_days = (dt_to - dt_from).days + 1\n",
    "    data_subset = data[(dt_from <= data.index) & (data.index <= dt_to)]\n",
    "    return len(data_subset) < delta_days\n",
    "\n",
    "def get_city_country(city_name):\n",
    "    if city_name not in cities_of_interest.keys():\n",
    "        raise Exception(f\"Please enter one of {cities_of_interest}.\")\n",
    "    return (city_name, cities_of_interest[city_name])\n",
    "\n",
    "def fetch_data_from_csv(type, city_name, **kwargs):\n",
    "    file_dir = data_dirs[type]\n",
    "    \n",
    "    #Empty dataframe for when there is no csv file\n",
    "    data = pd.DataFrame({'' : []})\n",
    "\n",
    "    try:\n",
    "        data = pd.read_csv(f'{file_dir}/{city_name}.csv', index_col='date', parse_dates=['date'])\n",
    "        if (kwargs):\n",
    "            return data[(kwargs['dt_from'] <= data.index) & (data.index <= kwargs['dt_to'])]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No historical {type} data found locally. Using API to get fresh data.\\n\")\n",
    "    return data\n",
    "\n",
    "def fetch_data_from_api(type, city_and_country, date_from, date_to):\n",
    "    # The first part of the tuple is the city and our csv data is organized by city name.\n",
    "    city_coords = query_lat_long(city_and_country)\n",
    "\n",
    "    if(type=='weather'):\n",
    "        data = query_historical_weather(city_coords, date_from, date_to)\n",
    "    elif(type=='pollution'):\n",
    "        data = query_historical_pollution(city_and_country, date_from, date_to)\n",
    "\n",
    "    #Write new csv file\n",
    "    dir_name = data_dirs[type]\n",
    "    data.to_csv(f'{dir_name}/{city_and_country[0]}.csv')\n",
    "    return data\n",
    "\n",
    "def partial_csv_update(type, from_api, city_and_country):\n",
    "    #Note that this is all of our CSV data for the city. no time filter\n",
    "    from_file = fetch_data_from_csv(type, city_and_country[0])\n",
    "\n",
    "    total_data = pd.concat([from_file, from_api])\n",
    "    unique_days = total_data.drop_duplicates()\n",
    "    unique_days = unique_days.sort_values('date')\n",
    "\n",
    "    dir_name = data_dirs[type]\n",
    "    unique_days.to_csv(f'{dir_name}/{city_and_country[0]}.csv')\n",
    "    return unique_days\n",
    "\n",
    "def filter_results_to_country(geoapi_response_data, country):\n",
    "    #If there are multiple cities with the same name, we choose the most populated\n",
    "    filter_by_country = [resp for resp in geoapi_response_data if resp['country_code'] == country]\n",
    "    # \n",
    "    sorted_by_pop = sorted(filter_by_country, key = lambda resp: resp['population'] if 'population' in resp else 0, reverse=True)\n",
    "    result = sorted_by_pop[0]\n",
    "\n",
    "    # Relevant subset of the result dict\n",
    "    return {key: result[key] for key in ('latitude', 'longitude', 'elevation', 'population')}\n",
    "\n",
    "def query_lat_long(city_country):\n",
    "    params_dict = {\n",
    "        'name': city_country[0],\n",
    "        #Default is 10 but since newcastle gives 9, we might hit the limit\n",
    "        'count': 100\n",
    "    }\n",
    "\n",
    "    # Since the user gives us more than 3 chars, the api performs fuzzy matching. So we do not\n",
    "    # need to worry abt spelling\n",
    "    resp = requests.get('https://geocoding-api.open-meteo.com/v1/search', params_dict)\n",
    "    data = resp.json()\n",
    "    \n",
    "    return filter_results_to_country(data['results'], city_country[1])\n",
    "\n",
    "def query_historical_weather(lat_long_elevation, date_from, date_to):\n",
    "    # Since we have dates and the api uses time, we need to convert from date to datetime\n",
    "    midnight_time = dt.min.time()\n",
    "    dt_from = dt.combine(date_from, midnight_time)\n",
    "    dt_to = dt.combine(date_to, midnight_time)\n",
    "    \n",
    "    location = Point(\n",
    "        lat_long_elevation['latitude'], \n",
    "        lat_long_elevation['longitude'], \n",
    "        lat_long_elevation['elevation'])\n",
    "\n",
    "    daily = Daily(location, start=dt_from, end=dt_to)\n",
    "    \n",
    "    # Ask meteostat to fill in any gaps in the data\n",
    "    daily.normalize()\n",
    "    data = daily.fetch()\n",
    "    \n",
    "    #tavg=Temp average (C).prcp=Total precipitation(mm). wdir=Wind direction(degrees)\n",
    "    #wspd=Average wind speed(km/h).wpgt=Wind peak gust(km/hr). pres=Sea-level air pressure(hpa)\n",
    "    #rhum=Relative humidity(does not work)\n",
    "    response = data[['tavg', 'prcp', 'wdir', 'wspd', 'wpgt', 'pres']]\n",
    "\n",
    "    #Since time is an index, simply calling rename does not work\n",
    "    tidy = response.rename_axis(index={\"time\": \"date\"})\n",
    "    #tidy['date'] = pd.to_datetime(tidy['date'], format='%y%m%d')\n",
    "\n",
    "    return tidy\n",
    "\n",
    "def get_weather(city_country):\n",
    "    coords = query_lat_long(city_country)\n",
    "    return query_historical_weather(coords)\n",
    "\n",
    "\n",
    "#From fetching measurements data notebook\n",
    "\n",
    "# TODO\n",
    "# 2. The dates are not the same for all cities.. Look into that\n",
    "# 3. Maybe count locations and provide that into the dataframe as well. \n",
    "#    It's relevent to know how many measures are in the city.\n",
    "# 4. Can we choose certain type of measures\n",
    "\n",
    "# Filter what city we want to get\n",
    "def filter_results_to_country(geoapi_response_data, country):\n",
    "    #If there are multiple cities with the same name, we choose the most populated\n",
    "    filter_by_country = [resp for resp in geoapi_response_data if resp['country_code'] == country]\n",
    "    # \n",
    "    sorted_by_pop = sorted(filter_by_country, key = lambda resp: resp['population'] if 'population' in resp else 0, reverse=True)\n",
    "    result = sorted_by_pop[0]\n",
    "\n",
    "    # Relevant subset of the result dict\n",
    "    return {key: result[key] for key in ('latitude', 'longitude', 'elevation', 'population')}\n",
    "\n",
    "def query_historical_pollution(city_country, date_from, date_to):\n",
    "    '''\n",
    "    This function takes in a city, parameter and date and writes data into a csv.file\n",
    "    Input:\n",
    "        city: name of a city (string)\n",
    "        ???parameter: List of strings that represent the parameters wanted to calculate\n",
    "        date_from: measurments after this date will be calculated\n",
    "        date_to: Measures until this date will be calculated\n",
    "    '''\n",
    "    \n",
    "    # Explicitly use v2 of the api http://dhhagan.github.io/py-openaq/api.html\n",
    "    api = openaq.OpenAQ(version ='v2')\n",
    "    # Get the longitude and latitude for the city\n",
    "    location = query_lat_long(city_country)\n",
    "    coords = f'{location[\"latitude\"]},{location[\"longitude\"]}'\n",
    "    \n",
    "    # Call the location api to check for the first date updated\n",
    "    locations = api.locations(coordinates = coords,radius = 10000,df = True)\n",
    "\n",
    "    min_date = locations[\"firstUpdated\"].min()\n",
    "    min_date = min_date.tz_convert(None)\n",
    "    min_date = pd.to_datetime(min_date) \n",
    "    \n",
    "    if min_date > date_from:\n",
    "        date_from = min_date  \n",
    "    \n",
    "    # Number of days we want measurements for\n",
    "    day_diff = (date_to - date_from).days\n",
    "    \n",
    "    # How we split the call between days to the API\n",
    "    split_days = 30\n",
    "\n",
    "    # Number of 30 day blocks in our range\n",
    "    number_months = day_diff // split_days\n",
    "\n",
    "    # Initialize the start date\n",
    "    start = date_from\n",
    "\n",
    "    # Add measurements data frame 30 days at a time\n",
    "    # An extra iteration for the remaining <30 days\n",
    "    for n in range(number_months + 1):\n",
    "        \n",
    "        # Find the end date\n",
    "        end = start + timedelta(days = split_days)\n",
    "        \n",
    "        # Fetch the data from the measurment api\n",
    "        try:\n",
    "            df_api = api.measurements(coordinates = coords, radius = 10000, df = True, \n",
    "                                        limit = 30000, parameter = [\"pm25\", \"pm10\"], value_from = 0,\n",
    "                                    date_from = start, date_to = end)\n",
    "        except KeyError:\n",
    "            print(f\"Opanaq API request with coordinates {coords} and date range {start}-{end} raised exception.\\n That can mean there is no data in that range.\")\n",
    "            return pd.DataFrame({'' : []})\n",
    "\n",
    "        # Start as the last end date\n",
    "        start = end\n",
    "\n",
    "        # For the first iteration create df\n",
    "        if n == 0: \n",
    "            df = df_api.copy()\n",
    "        # After the first iteration append the data\n",
    "        else:\n",
    "            df = df.append(df_api)\n",
    "    \n",
    "    ## Data prepping \n",
    "\n",
    "    # Change the index\n",
    "    df.index.name = 'Date.local'\n",
    "    df.reset_index(inplace=True)\n",
    "    df['date'] = df['Date.local'].dt.strftime('%Y-%m-%d')\n",
    "    df['value'] = df['value'].astype(float, errors = 'raise')\n",
    "\n",
    "    # Calculate mean, max and min value for each date\n",
    "    Result_mean = df.groupby(['date', 'parameter'],as_index=False)['value'].mean()\n",
    "    Result_max = df.groupby(['date', 'parameter'],as_index=False)['value'].max()\n",
    "    Result_min = df.groupby(['date', 'parameter'],as_index=False)['value'].min()\n",
    "\n",
    "    # Pivot the tables to wide format\n",
    "    ResultWide_mean = Result_mean.pivot_table(index='date',columns='parameter', values='value')\n",
    "    ResultWide_max = Result_max.pivot_table(index='date',columns='parameter', values='value')\n",
    "    ResultWide_min = Result_min.pivot_table(index='date',columns='parameter', values='value')\n",
    "\n",
    "    # Rename the columns to distinguish\n",
    "    ResultWide_mean.rename(columns={\"pm10\": 'pm10_mean', 'pm25': 'pm25_mean'}, inplace=True)\n",
    "    ResultWide_max.rename(columns={\"pm10\": 'pm10_max', 'pm25': 'pm25_max'}, inplace=True)\n",
    "    ResultWide_min.rename(columns={\"pm10\": 'pm10_min', 'pm25': 'pm25_min'}, inplace=True)\n",
    "\n",
    "    # Join mean and max first\n",
    "    df_first_join = pd.merge(ResultWide_mean, ResultWide_max, left_index=True, right_index=True)\n",
    "\n",
    "    # Join now to min\n",
    "    ResultWide = pd.merge(df_first_join, ResultWide_min, left_index=True, right_index=True)\n",
    "\n",
    "    # Change the index\n",
    "    ResultWide.index.name = 'date'\n",
    "    ResultWide.reset_index(inplace=True)\n",
    "\n",
    "    return ResultWide \n",
    "    \n",
    "# # Call the function\n",
    "city = 'Reykjavík'\n",
    "date_from = dt.strptime('01012020', \"%d%m%Y\").date()\n",
    "date_to = dt.strptime('01122021', \"%d%m%Y\").date()\n",
    "weather_data = fetch_weather_data(city)\n",
    "#pollution_data = fetch_pollution_data(city, date_from, date_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6732f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT CODE TO FIND CITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da43d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT CODE TO READ CSV FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b040376",
   "metadata": {},
   "source": [
    "# Pollution comparing socio-economic measures\n",
    "\n",
    "In order to produce a comprehensive report that aims to identify key factors that influence daily pollution in a certain city it is imperative to look into socio-economic factors. Intuativley population demographics would appear to play a big part in the pollution of certain cities. Alongside this the relative wealth of countries, their industry make-up and also education levels can all have implicit or explicit effects on pollution levels.\n",
    "\n",
    "In order to drill down into set areas a few factors were analysed. These were chosen as we belive they are primary risk factors to the pollution levels in a city. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT CODE TO PRODUCE GRAPHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b59cef",
   "metadata": {},
   "source": [
    "# Population \n",
    "\n",
    "The population of a city has big implications as to the levels of pollution. As a city grows in size so does the density. A higher population can cause strain on a city's infrastructure requirements, including education system and waste and seweage systems. According to a study by numbeo $^{1}$ out of the worlds 20 most polluted cities, 9 were in the top 20 for population density. \n",
    "\n",
    "Our hypothesis is that the the effects are of population are threefold - as a city increases in size education levels lag behind,. Lower eductaion levels can mean less awareness about pollution and health. Moreover, bigger cities are usually harder to police and more red tape and legistlation to pass. Lastly, a greater population will mean higher energy usage and a greater need for energy generation, which, is usally in the form of fossil fuels. \n",
    "\n",
    "INSERT GRAPHS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a7ba8",
   "metadata": {},
   "source": [
    "# GDP\n",
    "\n",
    "The GDP of a country would also have a big impact on pollution levels. Again, we have chosen to examine this measure due to the knock on or secondary effects GDP has on a pollution levels. During COP 21, it was heavility reported of China and India's desire to continue pollution given they are emerging nations. Emerging nations can sometimes view climate change and pollution level as an issue for the 'west' given high amounts of pollution during the industrial revolution in countries like the US and the UK.\n",
    "\n",
    "Our hypthesis is that the effects of GDP are two fold. A lower level of GDP will mean lower government budgets to invest in renewable energy and clean industry, dampening the effects of pollution. In addition to this, a lower level of GDP will mean a higher proportion of economic activity related to farming and non-service sector activities. These in-turn lead to slash and burn farming, mining and excavation and also a larger mass manufacturing sector. \n",
    "\n",
    "INSERT GRAPHS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3515f",
   "metadata": {},
   "source": [
    "# Other\n",
    "\n",
    "TELL ME WHAT OTHER MEANS AND I WILL TYPE SOMETHING UP\n",
    "\n",
    "# Events\n",
    "\n",
    "Lastly, events have a big impact on the pollution of a city, country and area. As touched upon during the introduction these events could be man-made or natural. Events such as the wildfire and volcanos will often produce large amounts of sulfur dioxide, carbon dioxide, and hydrogen fluoride. As we may examine, countries such as Iceland or Greece and more suseptible than others to events like this. \n",
    "\n",
    "Events can also be man made. We can classify COVID as an event and it was wideley reported that air pollution reduced by multiple factors during 2020 $^{2}$. This is just one example of an event causing air pollution to reduce, however, events such as strikes, legistlation changes would also have this effect. \n",
    "\n",
    "Contrary to this, our hypothesis is that events are mainly detremental to air quality. Sporting events being just one example that leads to a large number of people congregating in a set area leading to higher trasport pollution.\n",
    "\n",
    "INSERT GRAPHS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$^{1}$ https://www.numbeo.com/pollution/rankings.jsp\n",
    "\n",
    "$^{2}$ Marco Travaglio, Yizhou Yu, Rebeka Popovic, Liza Selley, Nuno Santos Leal, Luis Miguel Martins,\n",
    "Links between air pollution and COVID-19 in England,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d57308",
   "metadata": {},
   "source": [
    "# Pollution comparing weather\n",
    "\n",
    "Weather is also another factor that affects air pollution. As mentioned in the previous section, weather in the form of natural disaster can have a major impact on air pollution. However, the impact of weather of air pollution goes further than this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT WEATHER API CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c38d09",
   "metadata": {},
   "source": [
    "# Pollution and wind\n",
    "\n",
    "Weather systems such as wind and sunlight can have an impact on air pollution. During the 1950's London was named 'pea soup'. This was a combination of multiple multiple particulates and sulphur dioxide and occured when winds were low. Moreover, events such as acid rain are more common with greater levels of humidity and sunlight or UV rays can neautralise some pullutants through the form of a chemical reaction.\n",
    "\n",
    "INSERT GRAPHS \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83829e",
   "metadata": {},
   "source": [
    "# Temperature and wind\n",
    "\n",
    "The temperate of a country or city may also have a big impact on pollution. Hotter cities are often more prone to high levels of pollution as high temperatures are often associated with differing levels of pollution due to the movement of air. We hypothsise that hotter countries are prone to higher levels of pollution.\n",
    "\n",
    "INSERT GRAPHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788fc189",
   "metadata": {},
   "source": [
    "\n",
    "# Regression\n",
    "\n",
    "We aim to build a regression model to indicate the level of pollution on a set day based on multiple criteria. This will take the form of an air quality index for governements to use.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fc73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT REGRESSION CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
